{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bootstrap \n",
    "import sys \n",
    "import os\n",
    "\n",
    "\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "def read_data_csv(path=None,file_names=None, particular_word=None):\n",
    "    li = []\n",
    "\n",
    "    \n",
    "    for file in file_names:\n",
    "        if particular_word in file:\n",
    "            print(file)\n",
    "        #something isnt appending to files correctly\n",
    "            file = join(path, file)\n",
    "            df = pd.read_csv(file, index_col=None, header=0)\n",
    "       \n",
    "            li.append(df)\n",
    "    aggeregated_data = pd.concat(li, axis=0)\n",
    "    return aggeregated_data\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load data (#combine the two csv files into one data frame)\n",
    "\n",
    "\n",
    "# try:\n",
    "#     mac_path = '/Users/tlesick/Dropbox/data_sources/southern_ct_shoreline/'\n",
    "# #     data = #read_data_csv(mac_path, )\n",
    "    \n",
    "# except:\n",
    "# ml_server_path = '/home/betty/Dropbox/data_sources/southern_ct_shoreline/'\n",
    "# combine_files = [f for f in listdir(ml_server_path) if isfile(join(ml_server_path, f))]\n",
    "\n",
    "# data = read_data_csv(path=ml_server_path, file_names=combine_files, particular_word='county')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def read_directory(path=None):\n",
    "    path = '/home/betty/Dropbox/data_sources/southern_ct_shoreline/'\n",
    "    files = combine_files = [f for f in listdir(ml_server_path) if isfile(join(ml_server_path, f))]\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairfield_county_redfin_2020-03-19-10-18-28.csv\n",
      "litchfield_county_redfin_2020-03-19-10-10-25.csv\n",
      "new_haven_county_redfin_2020-03-19-10-15-39.csv\n",
      "windham_county_redfin_2020-03-19-10-14-06.csv\n",
      "new_london_county_redfin_2020-03-19-10-04-57.csv\n",
      "tolland_county_redfin_2020-03-19-10-17-44.csv\n",
      "middlesex_county_redfin_2020-03-19-10-15-11.csv\n",
      "hartford_county_redfin_2020-03-19-10-13-19.csv\n"
     ]
    }
   ],
   "source": [
    "#load data (#combine the two csv files into one data frame)\n",
    "\n",
    "\n",
    "# try:\n",
    "#     mac_path = '/Users/tlesick/Dropbox/data_sources/southern_ct_shoreline/'\n",
    "# #     data = #read_data_csv(mac_path, )\n",
    "    \n",
    "# except:\n",
    "ml_server_path = '/home/betty/Dropbox/data_sources/southern_ct_shoreline/'\n",
    "combine_files = [f for f in listdir(ml_server_path) if isfile(join(ml_server_path, f))]\n",
    "\n",
    "data = read_data_csv(path=ml_server_path, file_names=combine_files, particular_word='county')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# data.hist(bins=50, figsize=(20,15))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    revised_data  = data.drop( [\"SOLD DATE\", \"ADDRESS\",\"SALE TYPE\", \"CITY\", \"ZIP OR POSTAL CODE\",\n",
    "            \"URL (SEE http://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)\",\n",
    "            \"STATUS\", \"SOURCE\", \"MLS#\", \"FAVORITE\",\"NEXT OPEN HOUSE START TIME\", \"NEXT OPEN HOUSE END TIME\", \n",
    "          \"INTERESTED\", \"LOCATION\", \"HOA/MONTH\", \"STATE OR PROVINCE\", \"$/SQUARE FEET\",\n",
    "                ], axis=1)\n",
    "except: \n",
    "    pass\n",
    "\n",
    "#drop the rows that contain null values in city\n",
    "# data = data.dropna(subset=[\"CITY\"])\n",
    "#cannot stratify if has only one town\n",
    "# data = data[data.groupby('CITY').CITY.transform(len) > 2]\n",
    "# data = data.rename(columns={\"ZIP OR POSTAL CODE\": \"ZIP\"})\n",
    "\n",
    "# data = data[data.groupby('ZIP').ZIP.transform(len) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['ZIP'].value_counts().min()\n",
    "# data_prep = data[data.groupby('ZIP').ZIP.tranform(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create index\n",
    "data_with_id = revised_data.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is possible to stratify here \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_set, test_set = train_test_split(revised_data,\n",
    "                                       test_size=0.3, \n",
    "                                       random_state=42,\n",
    "                                       stratify=data[\"PROPERTY TYPE\"]\n",
    "                                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop price from training \n",
    "x_train = train_set.drop([\"PRICE\",\n",
    "                ], axis=1)\n",
    "y_train = train_set[\"PRICE\"].copy()\n",
    "\n",
    "x_test = test_set.drop([\"PRICE\",\n",
    "                ], axis=1)\n",
    "y_test = test_set[\"PRICE\"].copy()\n",
    "\n",
    "#median numbers to fill later\n",
    "housing_num_median = x_train.median().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "#all columns other than property category\n",
    "numerical_attributes = list(x_train.drop([\"PROPERTY TYPE\"], axis=1))\n",
    "#only property type \n",
    "categorical_attributes = list(x_train[[\"PROPERTY TYPE\"]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('one_hot', OneHotEncoder(sparse=False)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another option is to prep the data into a simple pipeline, this example utilizes a seperate numerical and categorical\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"numerical_attributes\", num_pipeline, numerical_attributes),\n",
    "    (\"categorical_attributes\", categorical_pipeline, categorical_attributes),\n",
    " \n",
    "])\n",
    "\n",
    "x_train_prepared = full_pipeline.fit_transform(x_train)\n",
    "x_test_prepared = full_pipeline.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one more scaling feature is to combine pipelines with\n",
    "#from sklearn.pipeline import FeatureUnion\n",
    "#setup the same way as pipeline or columntransfer\n",
    "\n",
    "\n",
    "# to see how it is transformed\n",
    "# x_train_transformed = pd.DataFrame(x_train_prepared, columns=x_train.columns,\n",
    "#                           index=x_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48147984924414716"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try training now\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train_prepared, y_train)\n",
    "#score is the r2\n",
    "lin_reg.score(x_train_prepared, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [ 117248. 1074176.  488960.  312576.  304384.]\n",
      "actual: [130000, 460000, 529000, 439900, 357000]\n"
     ]
    }
   ],
   "source": [
    "#lets see how it preformed \n",
    "some_data = x_test.iloc[:5]\n",
    "\n",
    "some_labels = y_test.iloc[:5]\n",
    "\n",
    "\n",
    "some_data_prepd = full_pipeline.transform(some_data)\n",
    "# some_data_prepd.shape\n",
    "lin_reg.predict(some_data_prepd)\n",
    "\n",
    "print('Predictions: ', lin_reg.predict(some_data_prepd))\n",
    "print('actual:', list(some_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308766.4204541251"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the mean square error for performance of the linear regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "housing_predictions = lin_reg.predict(x_train_prepared)\n",
    "lin_mse = mean_squared_error(y_train, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_scores(model, x, y):\n",
    "    print('Predictions: ', model.predict(x))\n",
    "    print('actual:', list(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31655406487257765"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using a decision tree model rather than the linear regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(x_train_prepared, y_train)\n",
    "tree_reg.score(x_test_prepared, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [ 200000. 1597000.  339000.  415000.  299900.]\n",
      "actual: [130000, 460000, 529000, 439900, 357000]\n"
     ]
    }
   ],
   "source": [
    "compare_scores(tree_reg, some_data_prepd, some_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tune the model by splitting the training/test data into representative groups\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, x_train_prepared, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_revised_rmnse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, x_train_prepared, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.77111135633174"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_predictions = tree_reg.predict(x_train_prepared)\n",
    "tree_mse = mean_squared_error(y_train, decision_tree_predictions)\n",
    "tree_root_mse = np.sqrt(tree_mse)\n",
    "tree_root_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [275836.58421116 456487.2401824  361944.90695936 398616.52273133\n",
      " 512661.62662429 299110.43076207 385997.36033947 378613.84796773\n",
      " 392379.13983692 242863.47761605]\n",
      "Mean:  370451.11372307816\n",
      "Standard_deviation:  77201.5882769269\n"
     ]
    }
   ],
   "source": [
    "#uses cross validation scores \n",
    "# E.G.cross_val_score(tree_reg, x_train_prepared, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "def display_scores(scores):\n",
    "    print(\"Scores: \", scores)\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"Standard_deviation: \", scores.std())\n",
    "display_scores(tree_revised_rmnse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [276438.70981403 400042.80879603 318104.04595663 370219.99035773\n",
      " 336868.52321622 494726.93796334 315344.27804872 316292.9925013\n",
      " 245622.32301833 179071.03724184]\n",
      "Mean:  325273.1646914162\n",
      "Standard_deviation:  81727.89952737435\n"
     ]
    }
   ],
   "source": [
    "#the linear regression actually preforms better on this smaller training set\n",
    "linear_regression_scores = cross_val_score(lin_reg, x_train_prepared, y_train, scoring='neg_mean_squared_error', cv=10)\n",
    "linear_regression_rmse_scores = np.sqrt(-linear_regression_scores)\n",
    "display_scores(linear_regression_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        10.000000\n",
       "mean     370451.113723\n",
       "std       81377.619313\n",
       "min      242863.477616\n",
       "25%      314819.049811\n",
       "50%      382305.604154\n",
       "75%      397057.177008\n",
       "max      512661.626624\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.sqrt(-scores)).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437589.38641534024"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVR model\n",
    "from sklearn.svm import SVR \n",
    "\n",
    "#i should make a function to call each modules easily with the fit, etc. like below\n",
    "svm_regression = SVR(kernel='linear')\n",
    "svm_regression.fit(x_train_prepared, y_train)\n",
    "housing_predictions = svm_regression.predict(x_train_prepared)\n",
    "svm_mse = mean_squared_error(y_train, housing_predictions)\n",
    "#unsure why sometimes it was run \n",
    "svm_rmse = np.sqrt(svm_mse)\n",
    "svm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [270209.41710451 281149.14411321 272465.4808719  273075.45629781\n",
      " 271705.83226637]\n",
      "actual: [130000, 460000, 529000, 439900, 357000]\n"
     ]
    }
   ],
   "source": [
    "compare_scores(svm_regression, some_data_prepd, some_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check multiple types of models at once \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#the first attempt will be 12 different combinations (3 estimators x 4 features)\n",
    "#the second attempt will do 2 estimators by 3 features so 6 combinations\n",
    "param_grid = [\n",
    "    #estimators are the number of 'trees', 'features' are the parameters\n",
    "    {'n_estimators':[3,10,3], 'max_features':[2,4,6,8]},\n",
    "    {'bootstrap':[False], 'n_estimators':[3, 10], 'max_features': [2,3,4]},\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                             max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators='warn', n_jobs=None,\n",
       "                                             oob_score=False, random_state=42,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 3]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_reg.fit(x_train_prepared, y_train)\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(x_train_prepared, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features=6, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307112.586932478 {'max_features': 2, 'n_estimators': 3}\n",
      "292026.5392362805 {'max_features': 2, 'n_estimators': 10}\n",
      "307112.586932478 {'max_features': 2, 'n_estimators': 3}\n",
      "307926.77870058286 {'max_features': 4, 'n_estimators': 3}\n",
      "282627.49475593324 {'max_features': 4, 'n_estimators': 10}\n",
      "307926.77870058286 {'max_features': 4, 'n_estimators': 3}\n",
      "295282.65456900315 {'max_features': 6, 'n_estimators': 3}\n",
      "270590.9173126652 {'max_features': 6, 'n_estimators': 10}\n",
      "295282.65456900315 {'max_features': 6, 'n_estimators': 3}\n",
      "309052.2963286775 {'max_features': 8, 'n_estimators': 3}\n",
      "279219.42669122014 {'max_features': 8, 'n_estimators': 10}\n",
      "309052.2963286775 {'max_features': 8, 'n_estimators': 3}\n",
      "305498.13064252655 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "280320.0515603753 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "336147.00787700835 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "282319.10761667724 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "316500.7783815188 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "297351.0993156829 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cv_results = grid_search.cv_results_\n",
    "for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators='warn',\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_sta...\n",
       "                                                   warm_start=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa8532eea58>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa8532eefd0>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#when looking for more combinations try randomcvsearch\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_regression = RandomForestRegressor(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(forest_regression, param_distributions=param_distribs,\n",
    "                                  n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "random_search.fit(x_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2335888550128886, 'BATHS'),\n",
       " (0.2026371410670815, 'SQUARE FEET'),\n",
       " (0.14786019945265713, 'LONGITUDE'),\n",
       " (0.14069813479748922, 'LATITUDE'),\n",
       " (0.10598364019902105, 'YEAR BUILT'),\n",
       " (0.09258329844156318, 'LOT SIZE'),\n",
       " (0.032115936662370385, 'BEDS'),\n",
       " (0.02613057148120026, 'DAYS ON MARKET'),\n",
       " (0.008851798222599504, 'Single Family Residential'),\n",
       " (0.003343153824670676, 'Vacant Land'),\n",
       " (0.0026977342043506794, 'Condo/Co-op'),\n",
       " (0.0021091384257115493, 'Multi-Family (2-4 Unit)'),\n",
       " (0.0013763569714035993, 'Multi-Family (5+ Unit)'),\n",
       " (2.404123699264871e-05, 'Townhouse')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the importance scores next to their columns\n",
    "category_encoder = full_pipeline.named_transformers_[\"categorical_attributes\"][\"one_hot\"]\n",
    "\n",
    "cat_one_hot_attributes = list(category_encoder.categories_[0])\n",
    "\n",
    "attributes = numerical_attributes + cat_one_hot_attributes\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Condo/Co-op', 'Multi-Family (2-4 Unit)', 'Multi-Family (5+ Unit)',\n",
       "        'Single Family Residential', 'Townhouse', 'Vacant Land'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I should probably remove the $/square feet, as there probably is fairly high correlation between the two\n",
    "#also latitude seems like an odd predictor of price, as all data is within the town..\n",
    "category_encoder.categories_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features=6, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_ \n",
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test[\"CITY\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = 177, x_test = 159\n",
    "# x_test[\"ZIP\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train[\"ZIP\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model on the test set\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x_test_prepared = full_pipeline.transform(x_test)\n",
    "\n",
    "\n",
    "final_predictions = final_model.predict(x_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469103.1013669399"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/betty/ml_env/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([            nan, 681705.03388118])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "                        loc=squared_errors.mean(),\n",
    "                        scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
